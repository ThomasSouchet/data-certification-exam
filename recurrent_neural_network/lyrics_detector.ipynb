{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics detector Challenge\n",
    "\n",
    "The goal for this challenge is to leverage your knowledge of Deep Learning to design and train a lyrics classifier. For a given verse $X$, our model should learn to predict the artist $y$. The dataset consists of lyrics scrapped from the Genius website.\n",
    "\n",
    "### Objectives:\n",
    "- Text preprocessing\n",
    "- Text embedding\n",
    "- Train a RNN to detect the artist behind a set of lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.205260Z",
     "start_time": "2021-06-25T17:22:11.396250Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "\n",
    "Our dataset contains around 4,000 verses of lyrics from different artists: Drake, Ed Sheeran and Kanye West (the verses are given in this order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.654079Z",
     "start_time": "2021-06-25T17:22:16.207433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, yeah I got one, Laurie got one and that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Drake</td>\n",
       "      <td>(Six) Yeah Yeah Yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Leave me out the comments, leave me out the no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Sins, I got sins on my mind And some M's, got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm from the four, but I love me a threesome D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Sins, I got sins on my mind And some M's, got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Tryin', tryin', tryin', tryin' I pray these ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Godfather with a garden full of snakes Call Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I been tryin', tryin', tryin', tryin' To get y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Yeah, heart just turned purple Three-sixty up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I been tryin', tryin', tryin', tryin' To get y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, yeah Pipe this shit up and I turn this sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Trendsetter, Ben Frank getter (Yeah) Whip what...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist                                              verse\n",
       "0   Drake                            Ayy, woah Ayy, ayy Yeah\n",
       "1   Drake  I'm makin' a change today The liquor been taki...\n",
       "2   Drake  I can't just be with you and only you Yeah, I ...\n",
       "3   Drake  Well, summer, all I did was rest, okay? And Ne...\n",
       "4   Drake  I'm makin' a change today The liquor been taki...\n",
       "5   Drake  Ayy, yeah I got one, Laurie got one and that t...\n",
       "6   Drake  Well, summer, all I did was rest, okay? And Ne...\n",
       "7   Drake  I'm makin' a change today The liquor been taki...\n",
       "8   Drake                               (Six) Yeah Yeah Yeah\n",
       "9   Drake  Leave me out the comments, leave me out the no...\n",
       "10  Drake  Sins, I got sins on my mind And some M's, got ...\n",
       "11  Drake  I'm from the four, but I love me a threesome D...\n",
       "12  Drake  Sins, I got sins on my mind And some M's, got ...\n",
       "13  Drake  Tryin', tryin', tryin', tryin' I pray these ni...\n",
       "14  Drake  Godfather with a garden full of snakes Call Po...\n",
       "15  Drake  I been tryin', tryin', tryin', tryin' To get y...\n",
       "16  Drake  Yeah, heart just turned purple Three-sixty up ...\n",
       "17  Drake  I been tryin', tryin', tryin', tryin' To get y...\n",
       "18  Drake  Ayy, yeah Pipe this shit up and I turn this sh...\n",
       "19  Drake  Trendsetter, Ben Frank getter (Yeah) Whip what..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/verses.csv\")\n",
    "data = raw_data.copy() # From now on, update `data` as you see fit and don't touch raw_data\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Have a look at the verse index 18th**. \n",
    "- What do you observe?\n",
    "- Clean verses from non standard characters using [`unidecode.unidecode()`](https://pypi.org/project/Unidecode/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "data['verse'] = data['verse'].apply(unidecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Check if some verses are duplicated.** \n",
    "- It can be frequent in music lyrics.\n",
    "- If so, remove them to avoid data leaks between train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.851521Z",
     "start_time": "2021-06-25T17:22:16.842793Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "And they say She's in the Class A Team Stuck in her daydream Been this way since 18 But lately, her face seems Slowly sinking, wasting Crumbling like pastries And they scream The worst things in life come free to us                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  20\n",
       "'Cause you need me, man, I don't need you You need me, man, I don't need you You need me, man, I don't need you at all You need me, man, I don't need you You need me, man, I don't need you You need me, man, I don't need you You need me, man, I don't need you at all You need me                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    10\n",
       "It's okay, it's okay, it's okay, it's okay It's okay, it's okay, you can run and tell your friends That I'm on, I'm on, I'm on, I'm on I'm on, I'm on, best believe I understand It's okay, it's okay, it's okay, it's okay It's okay, it's okay, you can run and tell my city I'm on, I'm on, I'm on, I'm on I'm on, come on, you can run and tell my city it's on                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       8\n",
       "I don't know if she's there Or if she cares It's taken you a long time to see You've got a goldfish memory This song's for you, not for me In misery                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      8\n",
       "Did you realize That you were a champion in their eyes?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   7\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ..\n",
       "Oooh, I got the 305 to my city I get it, I get it I get it, I get it, I swear that I get it I get it, I get it We did it, we did it We did it, we did it We so far from finished I brought you right back just so we can relive it                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1\n",
       "I said I know you see me chilling super low key If I'm with the right niggas, you can scoop an O.Z All the hustlers and the bouncers and the groupies know me Fresh denim, fresh shades in a coupe with no keys It start up when I touch the door And I encourage ladies to touch the floor As soon as we finish cutting, we can cut some more Then after you get high Make em, get em, girl you finna get low Lights dimmed down Got a lota dough plus a hit sound What you mean you ain't heard? I come highly recommended Everybody my friend even if they been offended They ain't really got a choice, it's an obvious decision You tryna make a come up in my city, it's a given Plus a nigga famous, plus I got a vision Not to mention having bars like a motherfucking prison They taking too long, their records on hold They threatened by my presence cause I make them feel old Guaranteed if they drop, they bragging bout what they sold Just remember where I live at, fifty thousand's going gold Holla at me when you see me, make yourself known Instead of hatin' on my music in the comfort of your home Nigga, be a man, you acting like a bitch I ain't acting like I'm rude I'm just acting like I'm rich, rich Riding with Weezy fucking Baby Are you the type of girl that me and Weezy fucking, baby? Cause I don't waste time, can't you see a nigga lazy And I might need some help But, you know, Weezy's fucking crazy     1\n",
       "Is anything I'm doin' brand new? Brand new (Brand new), brand new (Brand new), brand new Is anything I'm doin' brand new? (Is anything I'm doin' brand new?) Brand new (Brand new), brand new, brand new, brand new Oh, girl (Ayy, ayy, ayy) Is anything I'm doin' brand new? New, new, new, new, new Or is everything I'm doing too late? Late, late, late, late                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
       "Tweakin', tweakin' off that 2C-B, huh Is he gon' make it? TBD, huh Thought I was gon' run, DMC, huh I done died and lived again on DMT, huh See, this a type of high that won't come down This the type of high that get you gunned down Yeezy, Yeezy trollin' OD, huh Turn TMZ to Smack DVD, huh Russell Simmons wanna pray for me too I'ma pray for him 'cause he got MeToo'd Thinkin' what if that happened to me too Then I'm on E! News                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1\n",
       "I don't want your money, baby, oh (I don't want your money) You know I just want your time (Yeah, I want, yeah, I want your time) (She say) I don't want your money, baby, oh (I don't want your money) You know I just want your time (Time, time)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1\n",
       "Name: verse, Length: 3029, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['verse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.861084Z",
     "start_time": "2021-06-25T17:22:16.854026Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'data_loading',\n",
    "    shape=data.shape,\n",
    "    verses=data.verse[:50]\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis (given to you)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 **We check the number of unique artist and the number of verses per artist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.182432Z",
     "start_time": "2021-06-25T17:22:19.175936Z"
    }
   },
   "outputs": [],
   "source": [
    "data.artist.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 **For each artist, let's have a look at the top-10 most used words to see if they look similar?**\n",
    "\n",
    "We'll use Tensorflow's [`Tokenizer`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)'s index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.191343Z",
     "start_time": "2021-06-25T17:22:19.184174Z"
    }
   },
   "outputs": [],
   "source": [
    "drake = data[data.artist =='Drake'].verse\n",
    "ed = data[data.artist =='Ed Sheeran'].verse\n",
    "kanye = data[data.artist =='Kanye West'].verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.438880Z",
     "start_time": "2021-06-25T17:22:19.193277Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_drake = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_ed = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_kanye = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "tokenizer_drake.fit_on_texts(drake)\n",
    "tokenizer_ed.fit_on_texts(ed)\n",
    "tokenizer_kanye.fit_on_texts(kanye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.457776Z",
     "start_time": "2021-06-25T17:22:19.441016Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data={\n",
    "    \"Drake\": pd.Series(tokenizer_drake.index_word)[:10],\n",
    "    \"Ed Sheeran\": pd.Series(tokenizer_ed.index_word)[:10],\n",
    "    \"Kanye West\": pd.Series(tokenizer_kanye.index_word)[:10],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 **Let's quantify how much vocabulary do they have in common**\n",
    "\n",
    "- An artist **vocabulary** is the **set** of all unique used words\n",
    "- We compute the `ratio` of (i) the length of vocabulary they **share**, over (ii) the length of the **total** vocabulary of the dataset\n",
    "\n",
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "\n",
    "We'll use Python [`set.intersection()`](https://www.programiz.com/python-programming/methods/set/intersection) and [`set.union()`](https://www.programiz.com/python-programming/methods/set/union)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.465228Z",
     "start_time": "2021-06-25T17:22:19.460132Z"
    }
   },
   "outputs": [],
   "source": [
    "drake_vocabulary = set(tokenizer_drake.index_word.values())\n",
    "ed_vocabulary = set(tokenizer_ed.index_word.values())\n",
    "kanye_vocabulary = set(tokenizer_kanye.index_word.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.474902Z",
     "start_time": "2021-06-25T17:22:19.467454Z"
    }
   },
   "outputs": [],
   "source": [
    "common_vocabulary = drake_vocabulary.intersection(ed_vocabulary).intersection(kanye_vocabulary)\n",
    "global_vocabulary = drake_vocabulary.union(ed_vocabulary).union(kanye_vocabulary)\n",
    "\n",
    "ratio = len(common_vocabulary)/len(global_vocabulary)\n",
    "print(f\"{ratio*100:.2f}% of the artists' vocabulary is common\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Word Embedding\n",
    "We now need to think about embedding our sentences into numbers. We will be using [`gensim.models.Word2Vec`](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) to embed each word of the sentence and concatenate the embeddings of the words forming the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Transform the list of strings (verses) into a list of word sequences (a word sequence is a list of words contained in a string)**\n",
    "- Store these sequences of words in a new column `data[\"seq\"]` in your dataframe\n",
    "- You can use `tensorflow.keras.preprocessing.text.text_to_word_sequence` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.569442Z",
     "start_time": "2021-06-25T17:22:19.478291Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Let's check if we can cap the length of each sequences without losing too much information**\n",
    "- Plot the distribution of sequences lengths using the [`seaborn.kdeplot`](https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn-displot) function\n",
    "- Does it seem reasonable to limit ourself to 300 words per verse later on? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.783874Z",
     "start_time": "2021-06-25T17:22:19.572393Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Keep only the first `300` words of each sequences to reduce the useless long tail of long verses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.797635Z",
     "start_time": "2021-06-25T17:22:19.786221Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Train a `gensim.models.Word2Vec` model on your dataset** \n",
    "- You want to embed each word into vectors of dimension `100`\n",
    "- No words should be excluded\n",
    "- Give Word2Vec at least 50 epochs to be sure it converges\n",
    "- Store these lists of vectors in a new column `data[\"embed\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:26.587185Z",
     "start_time": "2021-06-25T17:22:19.799947Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:27.636650Z",
     "start_time": "2021-06-25T17:22:27.634359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check \n",
    "assert len(data['embed']) == len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Create your numpy array `X` of shape (number_of_verses, 300, 100)**\n",
    "\n",
    "- 300 words per verse (pad verses shorter than 300 with zeros at the end) \n",
    "- each words being a vector of size 100\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/lewagon/data-images/master/DL/padding.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.272086Z",
     "start_time": "2021-06-25T17:22:27.638449Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Create the numpy array `y` of shape `(n_verses, 3)` that contains the one-hot-encoded list of labels, for the RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.394015Z",
     "start_time": "2021-06-25T17:22:28.274638Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 We train/test split the dataset below for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.558686Z",
     "start_time": "2021-06-25T17:22:28.400774Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.803743Z",
     "start_time": "2021-06-25T17:22:29.563431Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'data_preprocessing',\n",
    "    n_zeros = np.sum(X == 0),\n",
    "    X_shape = X.shape,\n",
    "    y_shape = y.shape,\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 Run this code below if you haven't managed to build your own (X,Y) training sets. This will load them as solution\n",
    "\n",
    "```python\n",
    "! wget \\\n",
    "'https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_lyrics_solution.pickle'\n",
    "\n",
    "import pickle\n",
    "with open(\"data_lyrics_solution.pickle\", \"rb\") as file:\n",
    "    (X_train, y_train, X_test, y_test) = pickle.load(file)\n",
    "    \n",
    "! rm data_lyrics_solution.pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **First, store your baseline accuracy to beat as `score_baseline`**\n",
    "- Consider predicting always the most frequent artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:33.555223Z",
     "start_time": "2021-06-25T17:22:33.547120Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Create a RNN architecture to predict the artists `y`  given verses `X`** :\n",
    "\n",
    "- Keep it simple: use only one LSTM layer and one *hidden* dense layer between the input and output layers\n",
    "- Don't forget to take care of fake \"zeros\" added during preprocessing\n",
    "- Store it into the `model` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:27:09.448283Z",
     "start_time": "2021-06-25T17:27:08.796094Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Train your `model` on the `(X_train, y_train)` training set**\n",
    "- Use an appropriate loss\n",
    "- Adapt the learning rate of your optimizer if convergence is too slow/fast\n",
    "- Make sure your model does not overfit with appropriate control techniques\n",
    "\n",
    "💡 You will not be judged by the computing power of your computer, you can reach decent performance in less than 3 minutes of training without GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.790957Z",
     "start_time": "2021-06-25T17:27:09.537171Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Plot the training and validation losses through training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.814449Z",
     "start_time": "2021-06-25T17:28:13.793297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot below your train/val loss history\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Run also this code to save figure as jpg in path below (it's your job to ensure it works)\n",
    "fig = plt.gcf()\n",
    "plt.savefig(\"tests/history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Save your accuracy on test set as `score_test`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:29:15.350717Z",
     "start_time": "2021-06-25T17:29:14.925473Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧪 **Send your results below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:25:11.216908Z",
     "start_time": "2021-06-25T17:25:11.208773Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"network\",\n",
    "    loss = model.loss,\n",
    "    input_shape = list(model.input.shape),\n",
    "    layer_names = [layer.name for layer in model.layers],\n",
    "    final_activation = model.layers[-1].activation.__wrapped__._keras_api_names[0],\n",
    "    score_baseline = score_baseline,\n",
    "    score_test = score_test,\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "330.513px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
